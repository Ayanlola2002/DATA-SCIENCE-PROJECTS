{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Wrangling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxmNg6/KRT6pgojBiP/z6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayanlola2002/DATA-SCIENCE-PROJECTS/blob/master/Data_Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vs4GuGkmMBT",
        "outputId": "55a12862-ee9f-4f20-a235-d13204c6865b"
      },
      "source": [
        "#mounting Gdrive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pJYQGNJmYeQ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from datetime import date, datetime\r\n",
        "import holidays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ennCbmMYmdZj"
      },
      "source": [
        "df_5min=pd.read_csv('/content/drive/MyDrive/NEEDENERGY/data_five_min_id_47803.csv')\r\n",
        "df_hourly=pd.read_csv('/content/drive/MyDrive/NEEDENERGY/data_hourly_id_47803.csv')\r\n",
        "df_daily=pd.read_csv('/content/drive/MyDrive/NEEDENERGY/data_daily_id_47803.csv')\r\n",
        "df_monthly=pd.read_csv('/content/drive/MyDrive/NEEDENERGY/data_monthly_id_47803.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QUUqzO5meJX"
      },
      "source": [
        "##Wrangling Helper Functions to Use\r\n",
        "\"\"\"\r\n",
        "This function do the reading of data file from file path(i.e drive)\r\n",
        "\"\"\"\r\n",
        "def do_read_data(datafile, dateCol):\r\n",
        "    ''' Read the excel file'''\r\n",
        "    df = pd.read_excel(datafile, index_col= dateCol, parse_dates=True)\r\n",
        "    return df\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "This function Shows Information of the Data file\r\n",
        "Like The Header columns, Dimension of Data\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def do_data_information(datafile, info = False, head = True, shape = True):\r\n",
        "    ''' Look at the info of the data'''\r\n",
        "    \r\n",
        "    if not isinstance(datafile, pd.DataFrame):\r\n",
        "        df = read_data(datafile)\r\n",
        "    else:\r\n",
        "        df = datafile\r\n",
        "    \r\n",
        "    ## Information of data\r\n",
        "    if info:\r\n",
        "        df.info()\r\n",
        "        \r\n",
        "    print('--------------------------------------------------------------------')\r\n",
        "    print('First rows')\r\n",
        "    # Show first rows\r\n",
        "    if head:\r\n",
        "        print(df.head())\r\n",
        "        \r\n",
        "    print('--------------------------------------------------------------------')\r\n",
        "    print('Dimension of the data')\r\n",
        "    ## Dimension of data\r\n",
        "    if shape:\r\n",
        "        print(f'This data has {df.shape[0]} rows and {df.shape[1]} variables') \r\n",
        "        \r\n",
        "###This function returns the number of distinct values from any columns       \r\n",
        "def do_unique_values(df, col):\r\n",
        "    ''' Find the unique values of a columns'''\r\n",
        "    return df[col].nunique()\r\n",
        "\r\n",
        "\r\n",
        "###This function statistically describe the data values\r\n",
        "def do_description(df, col = None):\r\n",
        "    ''' Give the statistic summary'''\r\n",
        "    \r\n",
        "    ## Summary statistic\r\n",
        "    if col is not None:\r\n",
        "        stat = df[col].describe()\r\n",
        "    else:\r\n",
        "        stat = df.describe()\r\n",
        "\r\n",
        "    ## Change the name of the 50% index to median\r\n",
        "    idx = stat.index.tolist()\r\n",
        "    idx[5] = 'median'\r\n",
        "    stat.index = idx\r\n",
        "    return stat\r\n",
        "\r\n",
        "###This function finds % Missing values\r\n",
        "def check_missing_value(data):\r\n",
        "    ## percentage of missing values\r\n",
        "    n = data.isnull().sum().sort_values(ascending=False)/ len(data) * 100\r\n",
        "    return n\r\n",
        "\r\n",
        "def check_missing_values_table(df):\r\n",
        "  mis_val = df.isnull().sum()\r\n",
        "  mis_val_percent = 100 * df.isnull().sum() / len(df)\r\n",
        "  mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\r\n",
        "  mis_val_table_ren_columns = mis_val_table.rename(\r\n",
        "  columns = {0 : 'Missing Values', 1 : '% of Total Values'})\r\n",
        "  mis_val_table_ren_columns = mis_val_table_ren_columns[\r\n",
        "      mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\r\n",
        "  '% of Total Values', ascending=False).round(1)\r\n",
        "  print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \r\n",
        "      \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\r\n",
        "        \" columns that have missing values.\")\r\n",
        "  return mis_val_table_ren_columns\r\n",
        "\r\n",
        "\r\n",
        "###This function finds the amount of each values in a dataset\r\n",
        "def do_valueCount(data, col, perc = False):\r\n",
        "    ''' calculate the proportion in fraction or percentage'''\r\n",
        "    if not perc:\r\n",
        "      return data[col].value_counts()\r\n",
        "    else:\r\n",
        "      return data[col].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'    \r\n",
        "### This function count number of unique values for all columns in a dataset\r\n",
        "def do_nunique_value(df):\r\n",
        "  print('The Numver of unique values per columns are as follows')\r\n",
        "  print(df.agg(['nunique']).T)\r\n",
        "\r\n",
        "\r\n",
        "###For date time conversion start here   \r\n",
        "def do_date_col_convertion(df, column_name):\r\n",
        "  df[column_name]=pd.to_datetime(df[column_name])\r\n",
        "  return df[column_name]\r\n",
        "\r\n",
        "def do_time_col_convertion(df, column_name):\r\n",
        "    return pd.to_timedelta(df[column_name])\r\n",
        "\r\n",
        "\r\n",
        "def do_datepart_extraction(data):\r\n",
        "  data['date'] = pd.to_datetime(data['date'])\r\n",
        "  data['year'] = data['date'].dt.year\r\n",
        "  data['quarter']=data['date'].dt.quarter\r\n",
        "  data['month'] = data['date'].dt.month\r\n",
        "  data['weekday'] = data['date'].dt.weekday\r\n",
        "  data['day_name'] = data['date'].dt.day_name()\r\n",
        "  data['dayofyear'] = data['date'].dt.dayofyear\r\n",
        "  data['day'] =data['date'].dt.day\r\n",
        "  data['hour'] = data['date'].dt.hour\r\n",
        "  data['minute'] =data['date'].dt.minute\r\n",
        "  #data['Season']=data['month'].apply(do_year_season)\r\n",
        "  data['season'] = data.date.map(do_season_of_date)\r\n",
        "  data['day_section']=data['hour'].apply(do_day_sections)\r\n",
        "  return data\r\n",
        "   \r\n",
        "\r\n",
        "def do_season_of_date(date):\r\n",
        "  year = str(date.year)\r\n",
        "  seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\r\n",
        "              'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\r\n",
        "              'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\r\n",
        "  if date in seasons['spring']:\r\n",
        "    return 'spring'\r\n",
        "  if date in seasons['summer']:\r\n",
        "    return 'summer'\r\n",
        "  if date in seasons['autumn']:\r\n",
        "    return 'autumn'\r\n",
        "  else:\r\n",
        "    return 'winter'\r\n",
        "\r\n",
        "# Assuming df has a date column of type `datetime`\r\n",
        "#df['season'] = df.date.map(season_of_date)\r\n",
        "\r\n",
        "\r\n",
        "def do_day_sections(x):\r\n",
        "  if (x > 4) and (x <= 8):\r\n",
        "    return 'Early Morning'\r\n",
        "  elif (x > 8) and (x <= 12 ):\r\n",
        "    return 'Morning'\r\n",
        "  elif (x > 12) and (x <= 16):\r\n",
        "    return'Noon'\r\n",
        "  elif (x > 16) and (x <= 20) :\r\n",
        "    return 'Evening'\r\n",
        "  elif (x > 20) and (x <= 24):\r\n",
        "    return'Night'\r\n",
        "  elif (x <= 4):\r\n",
        "    return'Late Night'\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_holidays(startYear = 2018, endYear = 2025, countryCode = 'ZA'):\r\n",
        "  \"\"\"\r\n",
        "    Takes in a start and end date, and start and end year.\r\n",
        "    \r\n",
        "    Produces a dataframe with a daily date and columns:\r\n",
        "    holiday - 'Y' for holiday\r\n",
        "    holidayName - name of the holiday if holiday is 'Y'\r\n",
        "    \r\n",
        "    Returns a dataframe\r\n",
        "  \"\"\"\r\n",
        "  holidayDict = {}\r\n",
        "  for i in range(startYear, endYear):\r\n",
        "    for date, name in sorted(holidays.CountryHoliday(countryCode,years=[i]).items()):\r\n",
        "      holidayDict[date] = name\r\n",
        "      holiday_df = pd.DataFrame(list(holidayDict.items()),columns = ['day','holidayName'])\r\n",
        "      holiday_df['day'] = pd.to_datetime(holiday_df['day'], format='%Y-%M-%d').dt.date\r\n",
        "    return holiday_df\r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "def get_days(start = '1/1/2018',startYear = 2018, end = '31/12/2025',endYear = 2025, countryCode = 'ZA'):\r\n",
        "    \"\"\"\r\n",
        "    Takes in a start and end date, and start and end year.\r\n",
        "    \r\n",
        "    Produces a dataframe with a daily date and columns:\r\n",
        "    weekend - 'Y' for weendend and 'N' for workday\r\n",
        "    dayOfweek - numerical day of the week identifier 0 for monday\r\n",
        "    weekNum - numerical number of the week \r\n",
        "    holiday - 'Y' for holiday\r\n",
        "    holidayName - name of the holiday if holiday is 'Y'\r\n",
        "    \r\n",
        "    Returns a dataframe\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    #generate the range of daily dates\r\n",
        "    dates = pd.date_range(start = start, end = end)\r\n",
        "    date_df = pd.DataFrame(dates, columns = ['day'])\r\n",
        "    date_df['day'] = pd.to_datetime(date_df['day'], format='%Y-%M-%d')\r\n",
        "    country_holidays = get_holidays(startYear = startYear, endYear = endYear, countryCode = countryCode)\r\n",
        "    \r\n",
        "    date_df['dayName'] = pd.DatetimeIndex(date_df['day']).day_name()\r\n",
        "    date_df['dayOfWeek'] = date_df['day'].dt.dayofweek\r\n",
        "    date_df['weekend'] = date_df['dayOfWeek'].apply(lambda x: 'Y' if x>4 else 'N')\r\n",
        "    date_df['weekNum'] = date_df['day'].dt.week\r\n",
        "    date_df['holiday'] = date_df['day'].apply(lambda x: 'Y' if x in country_holidays['day'].values else 'N')\r\n",
        "    date_df['day'] = date_df['day'].dt.date\r\n",
        "    date_df = date_df.merge(country_holidays, on='day', how='left', indicator=False)\r\n",
        "    \r\n",
        "    date_df.to_csv(f'../data/public_holidays_weekends.csv', index=False)\r\n",
        "    return date_df\r\n",
        "\r\n",
        "###Functions to impute nan values for numerical varriable\r\n",
        "def Impute_nan(df):\r\n",
        "  numericalcol = [f for f in df_5min.columns if df_5min.dtypes[f] != 'object']\r\n",
        "  missing_col=df_5min[numericalcol].columns[df_5min[numericalcol].isnull().any()].tolist()\r\n",
        "  #Technique 1: Using mean to impute the missing values\r\n",
        "  for i in missing_col:\r\n",
        "    df.loc[df.loc[:,i].isnull(),i]=df.loc[:,i].mean()\r\n",
        "\r\n",
        "def Impute_na(df):\r\n",
        "  numericalcol = [f for f in df_5min.columns if df_5min.dtypes[f] != 'object']\r\n",
        "  missing_col=df_5min[numericalcol].columns[df_5min[numericalcol].isnull().any()].tolist()\r\n",
        "  #Technique 1: Using mean to impute the missing values\r\n",
        "  for i in missing_col:\r\n",
        "     df[i].fillna(mean,inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#df['holidays']=df['date'].apply(lambda(x: 'Hols' if x in get_holidays()['day'].values else 'Non-Hols'))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vTU_osHm44W",
        "outputId": "4f0f0dcd-bd1c-4bb4-89df-636e1ba8874e"
      },
      "source": [
        "#Data Description and Information for df_5min\r\n",
        "print(do_data_information(df_5min))\r\n",
        "print(do_data_information(df_hourly))\r\n",
        "print(do_data_information(df_daily))\r\n",
        "print(do_data_information(df_monthly))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "First rows\n",
            "                  date  ...                                   voltageHarmonics\n",
            "0  2020-03-15 18:15:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "1  2020-03-15 18:20:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "2  2020-03-15 18:25:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "3  2020-03-15 18:30:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "4  2020-03-15 18:35:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "--------------------------------------------------------------------\n",
            "Dimension of the data\n",
            "This data has 95649 rows and 15 variables\n",
            "None\n",
            "--------------------------------------------------------------------\n",
            "First rows\n",
            "                  date  ...                                   voltageHarmonics\n",
            "0  2020-03-15 18:00:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "1  2020-03-15 19:00:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "2  2020-03-15 20:00:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "3  2020-03-15 21:00:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "4  2020-03-15 22:00:00  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "--------------------------------------------------------------------\n",
            "Dimension of the data\n",
            "This data has 7979 rows and 15 variables\n",
            "None\n",
            "--------------------------------------------------------------------\n",
            "First rows\n",
            "         date  ...                                   voltageHarmonics\n",
            "0  2020-03-15  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "1  2020-03-16  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "2  2020-03-17  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "3  2020-03-18  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "4  2020-03-19  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "--------------------------------------------------------------------\n",
            "Dimension of the data\n",
            "This data has 335 rows and 15 variables\n",
            "None\n",
            "--------------------------------------------------------------------\n",
            "First rows\n",
            "         date  ...                                   voltageHarmonics\n",
            "0  2020-03-01  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "1  2020-04-01  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "2  2020-05-01  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "3  2020-06-01  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "4  2020-07-01  ...  [[], [], [], [], [], [], [], [], [], [], [], [...\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "--------------------------------------------------------------------\n",
            "Dimension of the data\n",
            "This data has 12 rows and 15 variables\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdG15O0DoIvf"
      },
      "source": [
        "Data Quality Information:\r\n",
        "df_5min : The data has 95649 rows and 15 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpwtZCr1oBhO",
        "outputId": "8a2abe05-9853-4f11-fc18-85024bec58a2"
      },
      "source": [
        "#Checking Missing Values by percentage\r\n",
        "print(check_missing_values_table(df_5min))\r\n",
        "print(check_missing_values_table(df_daily))\r\n",
        "print(check_missing_values_table(df_hourly))\r\n",
        "print(check_missing_values_table(df_monthly))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your selected dataframe has 15 columns.\n",
            "There are 0 columns that have missing values.\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, % of Total Values]\n",
            "Index: []\n",
            "Your selected dataframe has 15 columns.\n",
            "There are 0 columns that have missing values.\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, % of Total Values]\n",
            "Index: []\n",
            "Your selected dataframe has 15 columns.\n",
            "There are 0 columns that have missing values.\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, % of Total Values]\n",
            "Index: []\n",
            "Your selected dataframe has 15 columns.\n",
            "There are 0 columns that have missing values.\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, % of Total Values]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUDUqoBGTCcN",
        "outputId": "a98092a5-2c06-4d73-cfc5-6bd3ff23721d"
      },
      "source": [
        "#Checking number of Unique values\r\n",
        "print(do_nunique_value(df_5min))\r\n",
        "print(do_nunique_value(df_hourly))\r\n",
        "print(do_nunique_value(df_daily))\r\n",
        "print(do_nunique_value(df_monthly))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Numver of unique values per columns are as follows\n",
            "                  nunique\n",
            "date                95649\n",
            "timestamp           95649\n",
            "consumption         76377\n",
            "solar               50268\n",
            "alwaysOn              955\n",
            "gridImport          66188\n",
            "gridExport              1\n",
            "selfConsumption         2\n",
            "selfSufficiency      5594\n",
            "active              95512\n",
            "reactive            95595\n",
            "voltages              389\n",
            "phaseVoltages         389\n",
            "currentHarmonics        1\n",
            "voltageHarmonics        1\n",
            "None\n",
            "The Numver of unique values per columns are as follows\n",
            "                  nunique\n",
            "date                 7979\n",
            "timestamp            7979\n",
            "consumption          7963\n",
            "solar                7876\n",
            "alwaysOn              714\n",
            "gridImport           7946\n",
            "gridExport              1\n",
            "selfConsumption         2\n",
            "selfSufficiency      3092\n",
            "active               7979\n",
            "reactive             7979\n",
            "voltages              280\n",
            "phaseVoltages         280\n",
            "currentHarmonics        1\n",
            "voltageHarmonics        1\n",
            "None\n",
            "The Numver of unique values per columns are as follows\n",
            "                  nunique\n",
            "date                  335\n",
            "timestamp             335\n",
            "consumption           335\n",
            "solar                 333\n",
            "alwaysOn              333\n",
            "gridImport            335\n",
            "gridExport              1\n",
            "selfConsumption         2\n",
            "selfSufficiency       310\n",
            "active                335\n",
            "reactive              335\n",
            "voltages               95\n",
            "phaseVoltages          95\n",
            "currentHarmonics        1\n",
            "voltageHarmonics        1\n",
            "None\n",
            "The Numver of unique values per columns are as follows\n",
            "                  nunique\n",
            "date                   12\n",
            "timestamp              12\n",
            "consumption            12\n",
            "solar                  12\n",
            "alwaysOn               12\n",
            "gridImport             12\n",
            "gridExport              1\n",
            "selfConsumption         1\n",
            "selfSufficiency        12\n",
            "active                 12\n",
            "reactive               12\n",
            "voltages               10\n",
            "phaseVoltages          10\n",
            "currentHarmonics        1\n",
            "voltageHarmonics        1\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOEm9i04noWh"
      },
      "source": [
        "#Feature Engineering\r\n",
        "df_5min=do_datepart_extraction(df_5min)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "GVQWd5wypG0V",
        "outputId": "6c07006f-7157-47a7-fe0c-4152c055808c"
      },
      "source": [
        "df_5min.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>consumption</th>\n",
              "      <th>solar</th>\n",
              "      <th>alwaysOn</th>\n",
              "      <th>gridImport</th>\n",
              "      <th>gridExport</th>\n",
              "      <th>selfConsumption</th>\n",
              "      <th>selfSufficiency</th>\n",
              "      <th>active</th>\n",
              "      <th>reactive</th>\n",
              "      <th>voltages</th>\n",
              "      <th>phaseVoltages</th>\n",
              "      <th>currentHarmonics</th>\n",
              "      <th>voltageHarmonics</th>\n",
              "      <th>year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>month</th>\n",
              "      <th>weekday</th>\n",
              "      <th>day_name</th>\n",
              "      <th>dayofyear</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>season</th>\n",
              "      <th>day_section</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-15 18:15:00</td>\n",
              "      <td>1584288900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.1, 3.7, 0.0, -81.6, -60.0, 30.2, -230.6, -0...</td>\n",
              "      <td>[0.5, 0.9, 0.0, 55.4, 132.4, 14.0, 137.5, 0.2,...</td>\n",
              "      <td>[244.5, None, None]</td>\n",
              "      <td>[244.5, None, None]</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>winter</td>\n",
              "      <td>Evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-15 18:20:00</td>\n",
              "      <td>1584289200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.1, 3.8, 0.0, -82.2, -58.5, 30.5, -233.1, -0...</td>\n",
              "      <td>[0.5, 0.9, 0.0, 55.7, 131.9, 14.3, 144.3, 0.2,...</td>\n",
              "      <td>[246.1, None, None]</td>\n",
              "      <td>[246.1, None, None]</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>winter</td>\n",
              "      <td>Evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-15 18:25:00</td>\n",
              "      <td>1584289500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.1, 28.5, -26.5, -74.4, -79.2, 55.5, -228.5,...</td>\n",
              "      <td>[0.5, 19.0, 8.8, 79.6, 137.6, 29.4, 175.0, 0.4...</td>\n",
              "      <td>[246.4, None, None]</td>\n",
              "      <td>[246.4, None, None]</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>winter</td>\n",
              "      <td>Evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-15 18:30:00</td>\n",
              "      <td>1584289800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.5, 21.3, -18.6, -76.9, -54.7, 48.7, -227.8,...</td>\n",
              "      <td>[2.2, 13.3, 6.5, 72.4, 135.9, 24.8, 152.8, 0.8...</td>\n",
              "      <td>[246.0, None, None]</td>\n",
              "      <td>[246.0, None, None]</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>30</td>\n",
              "      <td>winter</td>\n",
              "      <td>Evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-15 18:35:00</td>\n",
              "      <td>1584290100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.1, 3.7, 0.0, -82.6, -33.2, 30.7, 96.6, 0.2,...</td>\n",
              "      <td>[0.5, 0.9, 0.0, 55.2, 128.1, 13.9, 87.7, 0.7, ...</td>\n",
              "      <td>[246.2, None, None]</td>\n",
              "      <td>[246.2, None, None]</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>35</td>\n",
              "      <td>winter</td>\n",
              "      <td>Evening</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 date      timestamp  consumption  ...  minute  season  day_section\n",
              "0 2020-03-15 18:15:00  1584288900000          0.0  ...      15  winter      Evening\n",
              "1 2020-03-15 18:20:00  1584289200000          0.0  ...      20  winter      Evening\n",
              "2 2020-03-15 18:25:00  1584289500000          0.0  ...      25  winter      Evening\n",
              "3 2020-03-15 18:30:00  1584289800000          0.0  ...      30  winter      Evening\n",
              "4 2020-03-15 18:35:00  1584290100000          0.0  ...      35  winter      Evening\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaKdvty73PgW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ-Yh2997i1q"
      },
      "source": [
        "#DATA QUALITY CHECK:\r\n",
        "*Data summary:\r\n",
        "* Raw_NeedEnergyApi_5min :\r\n",
        "Raw_Records: 95649 with 15 columns\r\n",
        "Cleaned(Current) :95649,\r\n",
        "\r\n",
        "* Raw_NeedEnergyApi_hourly :\r\n",
        "Raw_Record :7979 with 15 columns\r\n",
        "Cleaned(Current) :7979,\r\n",
        "* Raw_NeedEnergyApi_Daily :\r\n",
        "Raw_Records: 335 with 15 columns\r\n",
        "Cleaned (current):335\r\n",
        "* Raw_NeedEnergyApi_Monthly :\r\n",
        "Raw_records:12 with 15 columns\r\n",
        "cleaned =12\r\n",
        "* BASED ON THE FOLLOWING QUALITY DIMENSIONS:(ACCURACY,COMPELETENESS,VALUES FREE FROM CONTRADICTION)\r\n",
        "THE NEEDENERGY API 5MIN,HOURLY,DAILTY,MONTHLY DATASET has zero missing values.More data required for predictive analysis,\r\n",
        "\r\n",
        "## Feature Engineering:\r\n",
        "More features were extracted and created from the date column feature:\r\n",
        "* New features Generated :day,hour,month,year,day_name,\r\n",
        "seasons(winter,autumn,spring),day sections(Night,Evening,Afternoon)\r\n",
        "\r\n",
        "* Others:Jupyter starter files for \r\n",
        "Generalized Helper functions were created to generate seasons,day_sections,day,month,year,hour,quarter,were created for use for anyone willing to start-up cleaning or other task activities\r\n",
        "\r\n",
        "* In-Progress Helper function\r\n",
        "Public-holiday and many more for solar-iiradiance dataset.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpSvERxV7oqx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}